
@article{lemaire_triangulation_nodate,
	title = {Triangulation de {Delaunay} et arbres multidimensionnels},
	abstract = {Les travaux effectués lors de cette thèse concernent principalement la triangulation de Delaunay. On montre que la complexité en moyenne - en termes de sites inachevés - du processus de fusion multidimensionnelle dans l'hypothèse de distribution quasi-uniforme dans un hypercube est linéaire en moyenne. Ce résultat général est appliqué au cas du plan et permet d'analyser de nouveaux algorithmes de triangulation de Delaunay plus performants que ceux connus à ce jour. Le principe sous-jacent est de diviser le domaine selon des arbres bidimensionnels (quadtree, 2d-tree, bucket-tree. . . ) puis de fusionner les cellules obtenues selon deux directions. On étudie actuellement la prise en compte de contraintes directement pendant la phase de triangulation avec des algorithmes de ce type. De nouveaux algorithmes pratiques de localisation dans une triangulation sont proposés, basés sur la randomisation à partir d'un arbre binaire de recherche dynamique de type AVL, dont l'un est plus rapide que l'algorithme optimal de Kirkpatrick, au moins jusqu'à 12 millions de sites K Nous travaillons actuellement sur l'analyse rigoureuse de leur complexité en moyenne. Ce nouvel algorithme est utilisé pour construire " en-ligne " une triangulation de Delaunay qui est parmi les plus performantes des méthodes " en-ligne " connues à ce jour.},
	language = {French},
	author = {Lemaire, Christophe},
	pages = {227},
	file = {Lemaire - Triangulation de Delaunay et arbres multidimension.pdf:/home/nanox/Zotero/storage/SUJ6M3VV/Lemaire - Triangulation de Delaunay et arbres multidimension.pdf:application/pdf;Lemaire - Triangulation de Delaunay et arbres multidimension.pdf:/home/nanox/Zotero/storage/VW7LJCLV/Lemaire - Triangulation de Delaunay et arbres multidimension.pdf:application/pdf}
}

@misc{noauthor_streaming_nodate,
	title = {Streaming {Delaunay}: {I}/{O} and memory efficient {Computation} of {Delaunay} {Triangulations}},
	url = {http://www.cs.unc.edu/~isenburg/sd/},
	urldate = {2020-05-22},
	file = {Streaming Delaunay\: I/O and memory efficient Computation of Delaunay Triangulations:/home/nanox/Zotero/storage/AQALFEQZ/sd.html:text/html}
}

@article{makela_efficient_nodate,
	title = {Some {Efficient} {Procedures} for {Correcting} {Triangulated} {Models}},
	abstract = {This paper describes methods for handling efficiently a large class of problems encountered when dealing with 3D models represented by a collection of triangles in STL format. In spite of its drawbacks, the STL format has become a de facto industrial standard for transferring models to manufacturing processes generally known as Rapid Prototyping Techniques (RPT) or Solid Freeform Fabrication (SF2). As the accuracy and size of the workspace of such processes increases, so does the size of the models one wishes to manufacture. Therefore, the efficiency of application programs is an important consideration. Previous published work has focused on the problem of eliminating gaps in triangulated models. In addition to efficiency, this paper descrihes methods for dealing with other problems such as overlapping triangles and intersecting triangles. The algorithms have been implemented and tested in industry. The underlying data structures hased on adaptive space subdivision also allow the development of other efficient tools such as slicing.},
	language = {en},
	author = {Mäkelä, I},
	pages = {9},
	file = {Mäkelä - Some Efficient Procedures for Correcting Triangula.pdf:/home/nanox/Zotero/storage/6Y37KP2Q/Mäkelä - Some Efficient Procedures for Correcting Triangula.pdf:application/pdf}
}

@article{tate_smoothingfiltering_2005,
	title = {Smoothing/filtering {LiDAR} digital surface models. {Experiments} with loess regression and discrete wavelets},
	volume = {7},
	doi = {10.1007/s10109-005-0007-4},
	abstract = {This paper reports on the smoothing/filtering analysis of a digital surface model (DSM) derived from LiDAR altimetry for part of the River Coquet, Northumberland, UK using loess regression and the 2D discrete wavelet transform (DWT) implemented in the S-PLUS and R statistical packages. The chosen method of analysis employs a simple method to generate `noise' which is then added to a smooth sample of LiDAR data; loess regression and wavelet methods are then used to smooth/filter this data and compare with the original `smooth' sample in terms of RMSE. Various combinations of functions and parameters were chosen for both methods. Although wavelet analysis was effective in filtering the noise from the data, loess regression employing a quadratic parametric function produced the lowest RMSE and was the most effective.},
	journal = {Journal of Geographical Systems},
	author = {Tate, Nicholas and Brunsdon, Chris and Charlton, Martin and Fotheringham, Alexander and Jarvis, Claire},
	month = feb,
	year = {2005},
	pages = {273--290},
	file = {Full Text PDF:/home/nanox/Zotero/storage/2ZDMVPAC/Tate et al. - 2005 - Smoothingfiltering LiDAR digital surface models. .pdf:application/pdf}
}

@misc{noauthor_lidar_2018,
	title = {{LIDAR} {Filters}},
	url = {https://www.alluxa.com/optical-filter-applications/lidar-filters/},
	abstract = {Download/View LIDAR Whitepaper





In Our Catalog







532 nm LIDAR Filters







1064 nm LIDAR Filters







355 nm LIDAR Filters







	


Figure 1. Diagram illustrating the difference between single and multiple return signals from an aerial laser altimeter.
Image credit: Alluxa

LIDAR (Light Detection and Ranging) is a highly versatile active remote sensing technique that is used in Earth and atmospheric sciences, autonomous vehicles, urban planning, and many other applications. Some of the most important components of LIDAR sensors are the filters that isolate target signals, while preventing sunlight and other extraneous light from reaching the detector. A wide variety of applications and sensor types exist, from laser altimeters to Raman LIDAR systems, all with different return signal strengths and LIDAR filter requirements. Therefore, LIDAR filters must be designed with the specific application and sensor type in mind in order to maximize signal-to-noise ratio.
 Continue reading →},
	language = {en},
	urldate = {2020-04-23},
	journal = {Alluxa},
	month = jan,
	year = {2018},
	note = {Library Catalog: www.alluxa.com
Section: Learning Center},
	file = {Snapshot:/home/nanox/Zotero/storage/3EM8XHLQ/lidar-filters.html:text/html}
}

@phdthesis{desnogues_triangulations_1996,
	type = {phdthesis},
	title = {Triangulations et quadriques},
	url = {https://tel.archives-ouvertes.fr/tel-00771335},
	abstract = {Soit S un ensemble de points pris sur une surface F d'équation z = f(x,y) ; on projette S dans le plan (xOy), et on désire construire une triangulation de l'enveloppe convexe de la projection de S qui déterminera une approximation linéaire par morceaux de F, dont la qualité sera liée à une mesure de l'erreur d'approximation de la surface. Il a été récemment prouvé que la triangulation de Delaunay était optimale pour des critères de normes Lp, lorsqu'il s'agissait d'approcher linéairement toute fonction quadratique convexe, dans un espace de dimension quelconque. En revanche, très peu de recherches ont été menées lorsque la surface n'est pas convexe. Ce mémoire propose donc d'étudier l'approximation par une tri- angulation, pour des critères de normes L1 et L2, d'une surface non convexe d'équation la plus simple possible : le paraboloïde hyperbolique défini par z = x2 − y2. Une construction est ainsi donnée pour déterminer, de manière naturelle, les courbes de séparation d'un triangle ∆, c'est-à-dire les limites du plan pour lesquelles ∆ doit être conservé dans une triangulation localement op- timale du paraboloïde hyperbolique. Des algorithmes de triangulation qui font appel à diverses heuristiques fondées sur les courbes de séparation ont été abon- damment testés ; une amélioration significative par rapport à la triangulation de Delaunay a été mise en évidence. Une comparaison avec des triangulations glob- alement optimales, dont l'obtention n'est possible qu'au moyen de programmes de complexité exponentielle, prouve que ces algorithmes rendent finalement de "bonnes" triangulations. Les recherches montrent qu'un tel procédé peut facile- ment être généralisé à toutes les surfaces définies par des fonctions quadratiques, de la forme z = αx2 + βy2 + γxy + δ1x + δ2y + δ3.},
	language = {fr},
	urldate = {2020-04-06},
	school = {Université Nice Sophia Antipolis},
	author = {Desnogues, Pascal},
	month = dec,
	year = {1996},
	file = {Snapshot:/home/nanox/Zotero/storage/3D4F7MBK/tel-00771335.html:text/html}
}
